{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "from scipy.cluster import hierarchy as sch\n",
    "np.set_printoptions(suppress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Case3HistoricalPrices.csv')\n",
    "#df1 = pd.read_csv('trt.csv')\n",
    "#these are weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def getIVP(cov,**kargs):\n",
    "    # Compute the inverse-variance portfolio\n",
    "    ivp=1./np.diag(cov)\n",
    "    ivp/=ivp.sum()\n",
    "    return ivp\n",
    "\n",
    "def getClusterVar(cov,cItems):\n",
    "    # Compute variance per cluster\n",
    "    cov_=cov.loc[cItems,cItems] # matrix slice\n",
    "    w_=getIVP(cov_).reshape(-1,1)\n",
    "    cVar=np.dot(np.dot(w_.T,cov_),w_)[0,0]\n",
    "    return cVar\n",
    "\n",
    "def getQuasiDiag(link):\n",
    "    # Sort clustered items by distance\n",
    "    link=link.astype(int)\n",
    "    sortIx=pd.Series([link[-1,0],link[-1,1]])\n",
    "    numItems=link[-1,3] # number of original items\n",
    "    while sortIx.max()>=numItems:\n",
    "        sortIx.index=range(0,sortIx.shape[0]*2,2) # make space\n",
    "        df0=sortIx[sortIx>=numItems] # find clusters\n",
    "        i=df0.index;j=df0.values-numItems\n",
    "        sortIx[i]=link[j,0] # item 1\n",
    "        df0=pd.Series(link[j,1],index=i+1)\n",
    "        sortIx=sortIx.append(df0) # item 2\n",
    "        sortIx=sortIx.sort_index() # re-sort\n",
    "        sortIx.index=range(sortIx.shape[0]) # re-index\n",
    "    return sortIx.tolist()\n",
    "\n",
    "def getRecBipart(cov,sortIx):\n",
    "    # Compute HRP alloc\n",
    "    w=pd.Series(1,index=sortIx)\n",
    "    cItems=[sortIx] # initialize all items in one cluster\n",
    "    while len(cItems)>0:\n",
    "        cItems=[i[j:k] for i in cItems for j,k in ((0,len(i)//2), (len(i)//2,len(i))) if len(i)>1] # bi-section\n",
    "        for i in range(0,len(cItems),2): # parse in pairs\n",
    "            cItems0=cItems[i] # cluster 1\n",
    "            cItems1=cItems[i+1] # cluster 2\n",
    "            cVar0=getClusterVar(cov,cItems0)\n",
    "            cVar1=getClusterVar(cov,cItems1)\n",
    "            alpha=1-cVar0/(cVar0+cVar1)\n",
    "            w[cItems0]*=alpha # weight 1\n",
    "            w[cItems1]*=1-alpha # weight 2\n",
    "    return w\n",
    "\n",
    "def correlDist(corr):\n",
    "    # A distance matrix based on correlation, where 0<=d[i,j]<=1\n",
    "    # This is a proper distance metric\n",
    "    dist=((1-corr)/2.)**.5 # distance matrix\n",
    "    return dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = -1\n",
    "weights = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def allocate_portfolio(asset_prices):\n",
    "    #asset_prices = asset_prices.drop(index = index)\n",
    "    global counter\n",
    "    global weights\n",
    "    counter += 1\n",
    "    df.loc[len(df)] = asset_prices\n",
    "    cov,corr=df.cov(),df.corr()\n",
    "    dist=correlDist(corr)\n",
    "    link=sch.linkage(dist,'single')\n",
    "    sortIx=getQuasiDiag(link)\n",
    "    sortIx=corr.index[sortIx].tolist() # recover labels\n",
    "    df0=corr.loc[sortIx,sortIx]\n",
    "    hrp=np.array(getRecBipart(cov,sortIx))\n",
    "    \n",
    "    if(counter%63==0):\n",
    "        weights = hrp\n",
    "    return weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shakh\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:9: ClusterWarning: scipy.cluster: The symmetric non-negative hollow observation matrix looks suspiciously like an uncondensed distance matrix\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.12315032, 0.00546421, 0.00651947, 0.01704242, 0.01523349,\n",
       "       0.0172188 , 0.00978513, 0.01027385, 0.00437006, 0.01565367,\n",
       "       0.00211509, 0.00202549, 0.00470787, 0.00346642, 0.00090657,\n",
       "       0.00128729, 0.00073876, 0.00204557, 0.00176285, 0.00082157,\n",
       "       0.00093609, 0.00128422, 0.68359073, 0.06960007])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allocate_portfolio(np.array(df1.loc[0]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
